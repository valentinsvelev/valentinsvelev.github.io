---
layout: default
title: Projects
permalink: /projects.html
---

<div class="title-container">
    <h2 class="title-text">Projects</h2>
</div>

<div class="wrapper">
    <div class="container">
        <div class='project'>
            <h3>RAG4AL: A local RAG for academic literature <a href="https://www.python.org" target="_blank" class="icon-link"><i class="fab fa-python"></i></a></h3>
            <p class="indented">In this project, I will try and create a local retrieval augmented generation (RAG) app for academic literature. RAG was first introduced in <a href="https://dl.acm.org/doi/abs/10.5555/3495724.3496517">Lewis et al. (2020)</a> and can be summarized as an approach or a technique that leverages large language models (LLMs) to effeciently retrieve and synthesize factual information in a (local) database while minimizing hallucinations. In other words, it is a tool that allows the user to search for or synthesize text across many text files (e.g., PDF files) using the chat feature of a LLM (think of it like having a local ChatGPT but ChatGPT's knowledge base is limited to your text files). It involves vectorizing text documents (e.g., using <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">Sentence-BERT</a>), indexing them (e.g., using <a href="https://arxiv.org/abs/2401.08281">FAISS</a>) and then using a LLM with a chat feature (e.g., <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B">LLaMA 3</a>).</p>
        </div>
        <!-- <div class='project'>
            <h3>RoBERTa-BG: A RoBERTa-based state-of-the-art classification model for Bulgarian text <a href="https://www.python.org" target="_blank" class="icon-link"><i class="fab fa-python"></i></a></h3>
            <p class="indented">In a recent NLP conference in Varna, Bulgaria, three Bulgarian computer scientists presented two BERT- and GPT-based text classification models for Bulgarian that outperformed previous classifiers for Bulgarian.</p>
        </div> -->
        <!-- <div class='project'>
            <h3>Two sides of the same coin? The electorates of the <em>GRÜNE Schweiz</em> and the <em>Grünliberale Partei Schweiz</em> <a href="https://www.r-project.org" target="_blank" class="icon-link"><i class="fab fa-r-project"></i></a></h3>
            <p class="indented">Are the electorates of <em>GRÜNE Schweiz</em> and the <em>Grünliberale Partei Schweiz</em> similar? How do they differ? These are two of the questions Lukas Rudolph (University of Konstanz) and I will answer in this project.</p>
        </div> -->
        <!-- <div class='project'>
            <h3>The efficacy of synthetic data for market research: A GPT-2 and LLaMA 3 approach <a href="https://www.python.org" target="_blank" class="icon-link"><i class="fab fa-python"></i></a></h3>
            <p class="indented">Description of the project.</p>
        </div> -->
    </div>
</div>
